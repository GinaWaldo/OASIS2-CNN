{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import Drive to Colab"
      ],
      "metadata": {
        "id": "YJcGhAorIDyu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40dTt1sTgN2S",
        "outputId": "43db13cf-c8d2-439f-bbb0-52b9c53e0d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "_7e8E99SIJkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import skimage\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import ELU\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from skimage.transform import resize"
      ],
      "metadata": {
        "id": "bVpLGF7qggXM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading images for training"
      ],
      "metadata": {
        "id": "wSg0LlcjIWtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = os.path.join('/content/drive/MyDrive/', 'ParticionADNI1 (training)')\n",
        "imgpath = dirname + os.sep\n",
        "\n",
        "imagestrain1 = []\n",
        "directories = []\n",
        "dircount = []\n",
        "prevRoot=''\n",
        "cant=0\n",
        "\n",
        "print(\"leyendo imagenes de \",imgpath)\n",
        "\n",
        "for root, dirnames, filenames in os.walk(imgpath):\n",
        "  dirnames.sort()\n",
        "  for filename in filenames:\n",
        "      if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
        "          cant=cant+1\n",
        "          filepath = os.path.join(root, filename)\n",
        "          image = plt.imread(filepath)\n",
        "          if (image.shape!=(256,256)):\n",
        "            image_resized = resize(image, (256, 256), anti_aliasing=True)\n",
        "            imagestrain1.append(image_resized)\n",
        "          else:\n",
        "            imagestrain1.append(image)\n",
        "          b = \"Leyendo...\" + str(cant)\n",
        "          print (b, end=\"\\r\")\n",
        "          if prevRoot !=root:\n",
        "              print(root, cant)\n",
        "              prevRoot=root\n",
        "              directories.append(root)\n",
        "              dircount.append(cant)\n",
        "              cant=0\n",
        "dircount.append(cant)\n",
        "\n",
        "dircount = dircount[1:]\n",
        "dircount[0]=dircount[0]+1\n",
        "\n",
        "print('Directorios leidos:',len(directories))\n",
        "print(\"Imagenes en cada directorio\", dircount)\n",
        "print('suma Total de imagenes en subdirs:',sum(dircount))\n",
        "print('Directorios leidos:',len(directories))\n",
        "print(\"Imagenes en cada directorio\", dircount)\n",
        "print('suma Total de imagenes en subdirs:',sum(dircount))\n",
        "\n",
        "labels=[]\n",
        "indice=0\n",
        "for cantidad in dircount:\n",
        "    for i in range(cantidad):\n",
        "        labels.append(indice)\n",
        "    indice=indice+1\n",
        "print(\"Cantidad etiquetas creadas: \",len(labels))\n",
        "\n",
        "oasis=[]\n",
        "indice=0\n",
        "for directorio in directories:\n",
        "    name = directorio.split(os.sep)\n",
        "    print(indice , name[len(name)-1])\n",
        "    oasis.append(name[len(name)-1])\n",
        "    indice=indice+1"
      ],
      "metadata": {
        "id": "qQvakPNRgykH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading images for testing"
      ],
      "metadata": {
        "id": "Qb4wn7DtIfbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dirname = os.path.join('/content/drive/MyDrive/', 'ParticionADNI1 (test)')\n",
        "imgpath = dirname + os.sep\n",
        "\n",
        "imagestest1 = []\n",
        "directories1 = []\n",
        "dircount1 = []\n",
        "prevRoot=''\n",
        "cant=0\n",
        "\n",
        "print(\"leyendo imagenes de \",imgpath)\n",
        "\n",
        "for root, dirnames, filenames in os.walk(imgpath):\n",
        "  dirnames.sort()\n",
        "  for filename in filenames:\n",
        "      if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
        "          cant=cant+1\n",
        "          filepath = os.path.join(root, filename)\n",
        "          image = plt.imread(filepath)\n",
        "          if (image.shape!=(256,256)):\n",
        "            image_resized = resize(image, (256, 256), anti_aliasing=True)\n",
        "            imagestest1.append(image_resized)\n",
        "          else:\n",
        "            imagestest1.append(image)\n",
        "          b = \"Leyendo...\" + str(cant)\n",
        "          print (b, end=\"\\r\")\n",
        "          if prevRoot !=root:\n",
        "              print(root, cant)\n",
        "              prevRoot=root\n",
        "              directories1.append(root)\n",
        "              dircount1.append(cant)\n",
        "              cant=0\n",
        "dircount1.append(cant)\n",
        "\n",
        "dircount1 = dircount1[1:]\n",
        "dircount1[0] = dircount1[0]+1\n",
        "\n",
        "print('Directorios leidos:',len(directories1))\n",
        "print(\"Imagenes en cada directorio\", dircount1)\n",
        "print('suma Total de imagenes en subdirs:',sum(dircount1))\n",
        "print('Directorios leidos:',len(directories1))\n",
        "print(\"Imagenes en cada directorio\", dircount1)\n",
        "print('suma Total de imagenes en subdirs:',sum(dircount1))\n",
        "\n",
        "labels1=[]\n",
        "indice=0\n",
        "for cantidad in dircount1:\n",
        "    for i in range(cantidad):\n",
        "        labels1.append(indice)\n",
        "    indice=indice+1\n",
        "print(\"Cantidad etiquetas creadas: \",len(labels1))\n",
        "\n",
        "oasis=[]\n",
        "indice=0\n",
        "for directorio in directories1:\n",
        "    name = directorio.split(os.sep)\n",
        "    print(indice , name[len(name)-1])\n",
        "    oasis.append(name[len(name)-1])\n",
        "    indice=indice+1"
      ],
      "metadata": {
        "id": "tGpOlQCIg-Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preprocessing"
      ],
      "metadata": {
        "id": "Fl23X_ejIjxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(labels)\n",
        "X = np.array(imagestrain1, dtype=np.uint8) #convierto de lista a numpy\n",
        "\n",
        "x2 = []\n",
        "\n",
        "for i in X:\n",
        "    x2.append(skimage.color.gray2rgb(i))\n",
        "x2 = np.array(x2)\n",
        "\n",
        "X = x2\n",
        "\n",
        "tf.keras.applications.vgg16.preprocess_input(\n",
        "    X, data_format=None\n",
        ")\n",
        "\n",
        "y_test = np.array(labels1)\n",
        "x_test = np.array(imagestest1, dtype=np.uint8) #convierto de lista a numpy\n",
        "\n",
        "x3 = []\n",
        "\n",
        "for i in x_test:\n",
        "    x3.append(skimage.color.gray2rgb(i))\n",
        "x3 = np.array(x3)\n",
        "\n",
        "x_test = x3\n"
      ],
      "metadata": {
        "id": "JxIaKqd8hUiN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = X\n",
        "test_X = x_test\n",
        "train_Y = y\n",
        "test_Y = y_test\n",
        "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
        "print('Testing data shape : ', test_X.shape, test_Y.shape)\n",
        "\n",
        "train_X = train_X.astype('float32')\n",
        "test_X = test_X.astype('float32')\n",
        "train_X = train_X / 255.\n",
        "test_X = test_X / 255.\n",
        "\n",
        "# Change the labels from categorical to one-hot encoding\n",
        "train_Y_one_hot = to_categorical(train_Y)\n",
        "test_Y_one_hot = to_categorical(test_Y)\n",
        "\n",
        "# Display the change for category label using one-hot encoding\n",
        "print('Original label:', train_Y[0])\n",
        "print('After conversion to one-hot:', train_Y_one_hot[0])\n",
        "\n",
        "train_label = train_Y_one_hot\n",
        "valid_X = test_X\n",
        "valid_label = test_Y_one_hot"
      ],
      "metadata": {
        "id": "HvjA1iryhfTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the architecture and training the model"
      ],
      "metadata": {
        "id": "NKMt6Jp2IqOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-3\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(256,256,3))\n",
        "conv_base.summary()\n",
        "for layer in conv_base.layers:\n",
        "    layer.trainable = False\n",
        "conv_base.summary()\n",
        "\n",
        "oasis_model = Sequential()\n",
        "oasis_model.add(conv_base)\n",
        "oasis_model.add(Flatten())\n",
        "oasis_model.add(Dense(32, activation='linear'))\n",
        "oasis_model.add(ELU(alpha=1))\n",
        "oasis_model.add(Dropout(0.5))\n",
        "oasis_model.add(Dense(2, activation='softmax'))\n",
        "oasis_model.summary()\n",
        "\n",
        "oasis_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.legacy.Adagrad(learning_rate=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy', 'MeanSquaredError', 'AUC', 'Precision', 'Recall'])\n",
        "oasis_train = oasis_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n"
      ],
      "metadata": {
        "id": "xTowiRxnhk6K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}